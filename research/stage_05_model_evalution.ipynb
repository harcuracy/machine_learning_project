{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608045e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Dzuels Foundation\\\\mlproject\\\\notebook'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c477d65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dzuels Foundation\\mlproject\n"
     ]
    }
   ],
   "source": [
    "%cd ..\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05754442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from joblib import dump, load\n",
    "import mlflow\n",
    "import dagshub\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "from src.constant import *\n",
    "from src.logger import logging\n",
    "from src.exception import CustomException\n",
    "from src.utils import read_yaml,create_directory,save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ff8f83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-08 16:19:38,684] : httpx : INFO: HTTP Request: GET https://dagshub.com/api/v1/user \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as harcuracy\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as harcuracy\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-08 16:19:38,701] : dagshub : INFO: Accessing as harcuracy\n",
      "[2025-04-08 16:19:39,487] : httpx : INFO: HTTP Request: GET https://dagshub.com/api/v1/repos/harcuracy/machine_learning_project \"HTTP/1.1 200 OK\"\n",
      "[2025-04-08 16:19:40,314] : httpx : INFO: HTTP Request: GET https://dagshub.com/api/v1/user \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"harcuracy/machine_learning_project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"harcuracy/machine_learning_project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-08 16:19:40,327] : dagshub : INFO: Initialized MLflow to track repo \"harcuracy/machine_learning_project\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository harcuracy/machine_learning_project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository harcuracy/machine_learning_project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-08 16:19:40,331] : dagshub : INFO: Repository harcuracy/machine_learning_project initialized!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dagshub.init(repo_owner='harcuracy', repo_name='machine_learning_project', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3c5984",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass (frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir:Path\n",
    "    model_file:Path\n",
    "    test_data_file:Path\n",
    "    report_file:Path\n",
    "    target_column: str\n",
    "    mlflow_tracking_uri: str\n",
    "    all_params: dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_file_path=CONFIG_FILE_PATH,\n",
    "                 schema_file_path=SCHEMA_FILE_PATH,\n",
    "                 params_file_path=PARAMS_FILE_PATH,\n",
    "                 ):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.schema = read_yaml(schema_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "                \n",
    "        create_directory(self.config.artifact_root)\n",
    "        \n",
    "    def get_evaluation_config(self)-> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation\n",
    "        target_column = self.schema.TARGET_COLUMN.name\n",
    "        all_param = self.params.PARAMETERS.model.params\n",
    "        \n",
    "        create_directory(config.root_dir)\n",
    "        \n",
    "        model_trainer_config = ModelEvaluationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            model_file=config.model_file,\n",
    "            test_data_file=config.test_data_file,\n",
    "            report_file=config.report_file,\n",
    "            target_column=target_column,\n",
    "            all_params=all_param,\n",
    "            mlflow_tracking_uri=config.mlflow_tracking_uri\n",
    "        )\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40b54a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self,config:ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def eval_metric(self,y_true,y_pred):\n",
    "        rmse = root_mean_squared_error(y_true, y_pred, squared=False)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        \n",
    "        return rmse, mae, r2\n",
    "    \n",
    "    def log_into_mlflow(self):\n",
    "        model = load(self.config.model_file)\n",
    "        test_data = pd.read_csv(self.config.test_data_file)\n",
    "        X_test = test_data.drop(columns=[self.config.target_column])\n",
    "        y_test = test_data[self.config.target_column]\n",
    "        \n",
    "        mlflow.set_tracking_uri(self.config.mlflow_tracking_uri)\n",
    "        mlflow.set_experiment(experiment_name=\"model_evaluation\")\n",
    "        \n",
    "        with mlflow.start_run():\n",
    "            y_pred = model.predict(X_test)\n",
    "            rmse,mae, r2 = self.eval_metric(y_test, y_pred)\n",
    "            scores = {\n",
    "                \"rmse\" : rmse,\n",
    "                \"mae\": mae,\n",
    "                \"r2\": r2\n",
    "            }\n",
    "            save_json( scores, self.config.report_file)\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "    \n",
    "            mlflow.log_metrics(scores)\n",
    "            mlflow.sklearn.log_model(model, artifact_path=\"model_training\", registered_model_name=\"ElasticNet\")\n",
    "            \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd4c71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-08 16:20:09,442] : root : INFO: yaml file: config\\config.yaml loaded successfully\n",
      "[2025-04-08 16:20:09,448] : root : INFO: yaml file: schema.yaml loaded successfully\n",
      "[2025-04-08 16:20:09,453] : root : INFO: yaml file: params.yaml loaded successfully\n",
      "[2025-04-08 16:20:09,454] : root : INFO: Directory 'artifact' already exists.\n",
      "[2025-04-08 16:20:09,456] : root : INFO: Directory 'artifact/model_evaluation' already exists.\n",
      "[2025-04-08 16:20:11,264] : root : INFO: json file: artifact/model_evaluation/report.json saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/08 16:20:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'ElasticNet' already exists. Creating a new version of this model...\n",
      "2025/04/08 16:20:22 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ElasticNet, version 2\n",
      "Created version '2' of model 'ElasticNet'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run enthused-chimp-124 at: https://dagshub.com/harcuracy/machine_learning_project.mlflow/#/experiments/0/runs/cf8021ead77b4a1eb1c03ca1a0fd0460\n",
      "üß™ View experiment at: https://dagshub.com/harcuracy/machine_learning_project.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_evalution_config = config.get_evaluation_config()\n",
    "    model_evalution = ModelEvaluation(config=model_evalution_config)\n",
    "    model_evalution.log_into_mlflow()\n",
    "    \n",
    "except Exception as e:\n",
    "    logging.error(f\"Error in model evaluation: {str(e)}\")\n",
    "    raise CustomException(e, sys) from e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
